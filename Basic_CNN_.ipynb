{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SangMin316/Computer-Vision/blob/main/Basic_CNN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-0xKsX-lDLH"
      },
      "source": [
        "# 2021학년도 2학기 패턴인식 HW2: CNN\n",
        "\n",
        "HW2에서는 convolutional layer (CONV)와 pooling layer (POOL)의 forward propagation을 numpy로 구현하시오. Exercise 1,2,3,4를 잘 읽고 해당하는 함수를 구현하시오. (총 함수 4개 구현)\n",
        "\n",
        "**Notation**:\n",
        "- Superscript $[l]$ denotes an object of the $l^{th}$ layer. \n",
        "    - Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.\n",
        "\n",
        "\n",
        "- Superscript $(i)$ denotes an object from the $i^{th}$ example. \n",
        "    - Example: $x^{(i)}$ is the $i^{th}$ training example input.\n",
        "    \n",
        "    \n",
        "- Subscript $i$ denotes the $i^{th}$ entry of a vector.\n",
        "    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$, assuming this is a fully connected (FC) layer.\n",
        "    \n",
        "    \n",
        "- $n_H$, $n_W$ and $n_C$ denote respectively the height, width and number of channels of a given layer. If you want to reference a specific layer $l$, you can also write $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$. \n",
        "- $n_{H_{prev}}$, $n_{W_{prev}}$ and $n_{C_{prev}}$ denote respectively the height, width and number of channels of the previous layer. If referencing a specific layer $l$, this could also be denoted $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkVQ8qIelDLN"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - 패키지\n",
        "\n",
        "아래 셀을 실행시켜 구현에 필요한 패키지들을 import 한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAGIuh-UlDLO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svMAwNuHlDLP"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - 개요\n",
        "\n",
        "아래 명시된 CNN의 block들을 구현한다.\n",
        "\n",
        "- Convolution functions, including:\n",
        "    - Zero Padding\n",
        "    - Convolve window \n",
        "    - Convolution forward\n",
        "\n",
        "- Pooling functions, including:\n",
        "    - Pooling forward\n",
        "    - Create mask \n",
        "    - Distribute value\n",
        "\n",
        "    \n",
        "이번 과제에서는 위의 함수들을 `numpy`로 구현하시오. TensorFlow를 쓰면 같은 기능을 하는 함수들이 있지만, 이 과제는 numpy로만 구현한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLSvxmHmlDLP"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Convolutional Neural Networks\n",
        "\n",
        "라이브러리 등을 활용하여 convolution의 구현이 쉬워지기는 했지만, convolution은 Deep Learning에서 중요하고도 어려운 개념이다. convolution layer는 주어진 input volume을 다른 size의 output volume으로 변환시킨다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDpMfgZolDLQ"
      },
      "source": [
        "<a name='3-1'></a>\n",
        "### 3.1 - Zero-Padding\n",
        "\n",
        "Zero-padding은 이미지의 가장자리에 0의 픽셀들을 덧붙이는 작업이다.\n",
        "\n",
        "<caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><font color='purple'>  : <b>Zero-Padding</b><br> Image (3 channels, RGB) with a padding of 2. </center></caption>\n",
        "\n",
        "Padding의 이점:\n",
        "\n",
        "- CONV layer를 volume의 축소 없이 사용할 수 있다. 이는 깊은 신경망을 사용할수록 중요해진다. 특별한 케이스가 \"same\" convolution인데, 하나의 layer를 통과한 이후 height/width가 똑같이 보존되는 경우를 뜻한다.\n",
        "\n",
        "- 이미지 가장자리의 정보를 좀더 활용할수 있게 해준다. padding이 없다면, 이미지 가장자리의 픽셀들은 다음 layer에 매우 적은 영향력을 행사할 수 밖에 없다.\n",
        "\n",
        "<a name='ex-1'></a>\n",
        "### Exercise 1 - zero_pad\n",
        "아래 zero_pad 함수를 구현하시오. 이 함수는 주어진 dataset X에 포함된 m개의 이미지 모두의 가장자리에 zero를 padding한다. [np.pad 함수를 활용](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html). 예를 들어, array \"a\" of shape $(5,5,5,5,5)$ 를 2nd dimension에 `pad = 1`로 pad하고, 4th dimension에는 `pad = 3` 로 pad하고, 나머지 dimension에는 `pad = 0`으로 pad하고자 한다면, 다음과 같이 함수를 활용하여 구현 가능하다:\n",
        "```python\n",
        "a = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), mode='constant', constant_values = (0,0))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "5yVmtub6lDLR",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a14748505131e4100f550b8afcfb2d33",
          "grade": false,
          "grade_id": "cell-3096786c4bcad84a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: zero_pad\n",
        "\n",
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
        "    as illustrated in Figure 1.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n",
        "    \"\"\"\n",
        "    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)), mode = 'constant', constant_values = (0,0))\n",
        "    \n",
        "    return X_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU-trxOA342F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "eb34fac4-1b71-4a26-ef08-6f3e7633f3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape =\n",
            " (4, 3, 3, 2)\n",
            "x_pad.shape =\n",
            " (4, 9, 9, 2)\n",
            "x[1,1] =\n",
            " [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] =\n",
            " [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa6fd87a2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Test code\n",
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 3)\n",
        "print (\"x.shape =\\n\", x.shape)\n",
        "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
        "print (\"x[1,1] =\\n\", x[1, 1])\n",
        "print (\"x_pad[1,1] =\\n\", x_pad[1, 1])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0, :, :, 0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0, :, :, 0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaQ_-8BZlDLS"
      },
      "source": [
        "<a name='3-2'></a>\n",
        "### 3.2 - Single Step of Convolution \n",
        "\n",
        "A convolution unit은 다음과 같은 계산을 수행한다. (Figure 2 GIF 참조) \n",
        "\n",
        "- Input volume을 받아서,\n",
        "- Input의 모든 위치에 filter를 적용하여,\n",
        "- 또다른 크기의 volume을 출력한다.\n",
        "\n",
        "<caption><center> <u> <font color='purple'> <b>Figure 2</b> </u><font color='purple'>  : <b>Convolution operation</b><br> with a filter of 3x3 and a stride of 1 (stride = amount you move the window each time you slide) </center></caption>\n",
        "\n",
        "\n",
        "\n",
        "<a name='ex-2'></a>\n",
        "### Exercise 2 - conv_single_step\n",
        "이러한 convolution unit을 구축하기 위해, 이 중 한단계의 계산에 해당하는 single step of convolution을 구현하시오. 아래 conv_single_step 함수에서는 input 중 일부를 주어진 filter의 크기만큼만 잘라서 a_slice_prev로 만든 작은 input이 입력 argument로 주어지고, 여기에 같은 크기의 filter W를 element-wise로 곱해준다. 곱한 값들을 모두 더해서 하나의 값 Z로 만들고, 여기에 bias b를 더하여 최종 Z로 반환한다. 따라서 conv_single_step 함수는 a single real-valued 값 Z를 반환한다.\n",
        "    \n",
        "[Hint](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "26QD897RvLwK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "lvp4HYomlDLT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9ef959e74c801cce52d46fb16fb0ba0d",
          "grade": false,
          "grade_id": "cell-bd1b8f799894d4e0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: conv_single_step\n",
        "\n",
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "    of the previous layer.\n",
        "    \n",
        "    Arguments:\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "    Returns:\n",
        "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "    \"\"\"\n",
        "\n",
        "    s = np.multiply(a_slice_prev, W)\n",
        "    Z = np.sum(s)\n",
        "    Z = Z + float(b)\n",
        "    return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "i7LauiHDlDLT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "794e89cc8202e83b9752d097a4c0d730",
          "grade": true,
          "grade_id": "cell-a77e63b4119ac3b9",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48da10c1-6bbd-4082-be60-7de29bc13247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z = -6.999089450680221\n"
          ]
        }
      ],
      "source": [
        "# Test code\n",
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)\n",
        "# Expected output: Z=-23.1602"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgvrr-rYlDLU"
      },
      "source": [
        "<a name='3-3'></a>\n",
        "### 3.3 - Convolutional Neural Networks - Forward Pass\n",
        "\n",
        "Forward pass에서는 여러 개의 filter를 받아서 input과 convolution을 계산한다. 각 filter에 대한 convolution은 2D matrix를 출력한다. 이러한 2D matrix를 쌓아서 3D volume으로 만들어 최종적으로 반환한다. \n",
        "\n",
        "\n",
        "<a name='ex-3'></a>\n",
        "### Exercise 3 -  conv_forward\n",
        "Filters `W`를 input activation `A_prev`와 convolution하는 함수를 구현하시오. 이 함수는 다음과 같은 값들을 입력 argument로 받는다.\n",
        "\n",
        "* `A_prev`: 이전 layer에서 출력한 activation (for a batch of m inputs); \n",
        "* `W`: Filter weights.  Filter window size는 `f` by `f`.\n",
        "* `b`: Bias vector. 각 filter마다 bias 값 하나씩.\n",
        "\n",
        "Hyperparameter인 stride와 padding에도 access 가능.\n",
        "\n",
        "**Hint**: \n",
        "1. \"a_prev\" (shape (5,5,3)) 의 좌상단 코너 지점 2x2 크기의 slice를 선택하려면:\n",
        "```python\n",
        "a_slice_prev = a_prev[0:2,0:2,:]\n",
        "```\n",
        "위의 코드는 height 2, width 2, and depth 3의 3D slice를 제공한다. Depth는 채널의 개수이다. 이 코드는 `start/end` index를 활용하여 `a_slice_prev`를 정의하는데 유용할 것이다.\n",
        "\n",
        "2. `a_slice`를 정의하려면 이 slice의 코너점 네개 `vert_start`, `vert_end`, `horiz_start`, `horiz_end`를 정의해야 한다. \n",
        "\n",
        "<caption><center> <u> <font color='purple'> <b>Figure 3</b> </u><font color='purple'>  : <b>Definition of a slice using vertical and horizontal start/end (with a 2x2 filter)</b> <br> This figure shows only a single channel.  </center></caption>\n",
        "\n",
        "\n",
        "**Reminder**:\n",
        "    \n",
        "convolution 계산의 input shape과 output shape 관계에 관한 공식:\n",
        "    \n",
        "$$n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1$$\n",
        "$$n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1$$\n",
        "$$n_C = \\text{number of filters used in the convolution}$$\n",
        "    \n",
        "이번 함수를 계산하는데 있어서 일단 vectorization은 걱정하지 말고, for-loop으로 모두 계산하시오.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6yaM1kulDLU"
      },
      "source": [
        "#### Additional Hints :\n",
        "\n",
        "\n",
        "* 아래 변수들에게는 Array slicing 을 활용 (e.g.`varname[0:1,:,3:5]`)  \n",
        "  `a_prev_pad` ,`W`, `b`  \n",
        "\n",
        "* `vert_start`, `vert_end`, `horiz_start`, `horiz_end` 들을 구하기 위해서는 이전 layer들의 index들을 활용\n",
        "\n",
        "* `a_slice_prev` 는 height, width, depth가 있어야 한다.\n",
        "\n",
        "* `a_prev_pad` 는 `A_prev_pad`의 subset이다.   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "rRSLT8D7lDLV",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "812d5c174c04b75b9edaf9b77ce3da72",
          "grade": false,
          "grade_id": "cell-00b35b01091c3cdc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: conv_forward\n",
        "\n",
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, \n",
        "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    # YOUR CODE STARTS HERE\n",
        "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "\n",
        "    # Retrieve dimensions from W's shape (≈1 line)\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "\n",
        "    # Retrieve information from \"hparameters\"\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
        "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
        "    n_H = int((n_H_prev - f + (2 * pad)) / stride + 1)\n",
        "    n_W = int((n_W_prev - f + (2 * pad)) / stride + 1)\n",
        "    # Initialize the output volume Z with zeros. (≈1 line)\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Create A_prev_pad by padding A_prev\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):               # loop over the batch of training examples\n",
        "        a_prev_pad = A_prev[i]               # Select ith training example's padded activation\n",
        "        for h in range(n_H):           # loop over vertical axis of the output volume\n",
        "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "            vert_start = stride * h\n",
        "            vert_end = stride * h + f\n",
        "            \n",
        "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
        "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = stride * w + f\n",
        "                \n",
        "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
        "                                        \n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
        "                    a_slice_prev = A_prev_pad[i, vert_start:vert_end, horiz_start:horiz_end, :]                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
        "                    # weights = None\n",
        "                    # biases = None\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[:, :, :, c], b[:, :, :, c])\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "VpVN2Fi0lDLV",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f3dea502cdd13258e8b23dbb0a19402a",
          "grade": true,
          "grade_id": "cell-429520eed87675d9",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a00d2d-37c3-4a22-88af-991f0fb4cacd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z's mean =\n",
            " 0.5511276474566768\n",
            "Z[0,2,1] =\n",
            " [-2.17796037  8.07171329 -0.5772704   3.36286738  4.48113645 -2.89198428\n",
            " 10.99288867  3.03171932]\n",
            "cache_conv[0][1][2][3] =\n",
            " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
          ]
        }
      ],
      "source": [
        "# Test code\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 7, 4)\n",
        "W = np.random.randn(3, 3, 4, 8)\n",
        "b = np.random.randn(1, 1, 1, 8)\n",
        "hparameters = {\"pad\" : 1,\n",
        "               \"stride\": 2}\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "print(\"Z's mean =\\n\", np.mean(Z))\n",
        "print(\"Z[0,2,1] =\\n\", Z[0, 2, 1])\n",
        "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])\n",
        "\n",
        "# Expected output:\n",
        "# Z's mean = 8.197763428003048\n",
        "# Z[0,2,1] =\n",
        "# [-51.13640902  10.93358694 -16.67526948  25.91524569  17.48959664\n",
        "#  61.96334769  15.97168671  21.00441112]\n",
        "# cache_conv[0][1][2][3] =\n",
        "# [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDWqObd4lDLV"
      },
      "source": [
        "최종적으로, CONV layer는 activation을 포함해야 하므로 아래의 코드가 추가 되어야 하지만, 이 과제에서는 생략한다. \n",
        "\n",
        "```python\n",
        "# Convolve the window to get back one output neuron\n",
        "Z[i, h, w, c] = ...\n",
        "# Apply activation\n",
        "A[i, h, w, c] = activation(Z[i, h, w, c])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu6vT1w4lDLW"
      },
      "source": [
        "<a name='4'></a>\n",
        "## 4 - Pooling Layer \n",
        "\n",
        "Pooling layer (POOL)는 input의 height와 width를 줄여준다. 이 단계는 계산량을 줄이고 input의 position에 invariant한 feature detector를 만드는데 도움을 준다. Pooling 방식에는 max-pooling과 average-pooling이 있다.\n",
        "\n",
        "Pooling layer는 backpropagation을 통해 train해야 할 parameter는 없지만, window size $f$와 filter를 옮기는 간격 stride와 같은 hyperparameter는 존재한다. \n",
        "\n",
        "\n",
        "<a name='ex-4'></a>\n",
        "### Exercise 4 - pool_forward\n",
        "\n",
        "아래 pool_forward 함수에 MAX-POOL과 AVG-POOL을 하나의 함수에 모두 구현하시오. \n",
        "\n",
        "**Reminder**:\n",
        "Padding은 없으므로, pooling 전후의 input shape과 output shape의 관계는 다음과 같다.\n",
        "\n",
        "$$n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f}{stride} \\Bigr\\rfloor +1$$\n",
        "\n",
        "$$n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - f}{stride} \\Bigr\\rfloor +1$$\n",
        "\n",
        "$$n_C = n_{C_{prev}}$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "VUOtMdI4lDLW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0201a499bc4a2249c65fa3a736985fac",
          "grade": false,
          "grade_id": "cell-aed533a126205ca2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: pool_forward\n",
        "\n",
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the forward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from the input shape\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    # YOUR CODE STARTS HERE\n",
        "    for i in range(m):                         # loop over the training examples\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "            vert_start = stride * h\n",
        "            vert_end = stride * h + f\n",
        "            \n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
        "                horiz_start = stride * w\n",
        "                horiz_end = stride * w + f\n",
        "                \n",
        "                for c in range (n_C):            # loop over the channels of the output volume\n",
        "                    \n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "\n",
        "                    \n",
        "                    # Compute the pooling operation on the slice. \n",
        "                    # Use an if statement to differentiate the modes. \n",
        "                    # Use np.max and np.mean.\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    \n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    # Making sure your output shape is correct\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    return A, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "j5xkt3i4lDLX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "41872940d42f284c524d3b66eaf3c205",
          "grade": true,
          "grade_id": "cell-ae96f27f888cec37",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e6604c-4567-4e7b-cf07-bb7d14033ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode = max\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A[1, 1] =\n",
            " [[1.96710175 0.84616065 1.27375593]\n",
            " [1.96710175 0.84616065 1.23616403]\n",
            " [1.62765075 1.12141771 1.2245077 ]]\n",
            "mode = average\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A[1, 1] =\n",
            " [[ 0.44497696 -0.00261695 -0.31040307]\n",
            " [ 0.50811474 -0.23493734 -0.23961183]\n",
            " [ 0.11872677  0.17255229 -0.22112197]]\n"
          ]
        }
      ],
      "source": [
        "# Test Case 1: stride of 1\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 1, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"max\")\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[1, 1] =\\n\", A[1, 1])\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[1, 1] =\\n\", A[1, 1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzIQCsTflDLX"
      },
      "source": [
        "**Expected output**\n",
        "\n",
        "```\n",
        "mode = max\n",
        "A.shape = (2, 3, 3, 3)\n",
        "A[1, 1] =\n",
        " [[1.96710175 0.84616065 1.27375593]\n",
        " [1.96710175 0.84616065 1.23616403]\n",
        " [1.62765075 1.12141771 1.2245077 ]]\n",
        "\n",
        "mode = average\n",
        "A.shape = (2, 3, 3, 3)\n",
        "A[1, 1] =\n",
        " [[ 0.44497696 -0.00261695 -0.31040307]\n",
        " [ 0.50811474 -0.23493734 -0.23961183]\n",
        " [ 0.11872677  0.17255229 -0.22112197]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YcdwvoA9lDLX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "756f8dfdbdba11c66fc0b342d8be23c4",
          "grade": true,
          "grade_id": "cell-2bc34b23ee92311b",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f9b086-ef4f-4681-975b-5afb4e5b4fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode = max\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A[0] =\n",
            " [[[1.74481176 0.90159072 1.65980218]\n",
            "  [1.74481176 1.6924546  1.65980218]]\n",
            "\n",
            " [[1.13162939 1.51981682 2.18557541]\n",
            "  [1.13162939 1.6924546  2.18557541]]]\n",
            "\n",
            "mode = average\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A[1] =\n",
            " [[[-0.17313416  0.32377198 -0.34317572]\n",
            "  [ 0.02030094  0.14141479 -0.01231585]]\n",
            "\n",
            " [[ 0.42944926  0.08446996 -0.27290905]\n",
            "  [ 0.15077452  0.28911175  0.00123239]]]\n"
          ]
        }
      ],
      "source": [
        "# Test Case 2: stride of 2\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[0] =\\n\", A[0])\n",
        "print()\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[1] =\\n\", A[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rtOdxgUlDLX"
      },
      "source": [
        "**Expected Output:**\n",
        "    \n",
        "```\n",
        "mode = max\n",
        "A.shape = (2, 2, 2, 3)\n",
        "A[0] =\n",
        " [[[1.74481176 0.90159072 1.65980218]\n",
        "  [1.74481176 1.6924546  1.65980218]]\n",
        "\n",
        " [[1.13162939 1.51981682 2.18557541]\n",
        "  [1.13162939 1.6924546  2.18557541]]]\n",
        "\n",
        "mode = average\n",
        "A.shape = (2, 2, 2, 3)\n",
        "A[1] =\n",
        " [[[-0.17313416  0.32377198 -0.34317572]\n",
        "  [ 0.02030094  0.14141479 -0.01231585]]\n",
        "\n",
        " [[ 0.42944926  0.08446996 -0.27290905]\n",
        "  [ 0.15077452  0.28911175  0.00123239]]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ7rT1bMlDLX"
      },
      "source": [
        "**Congratulations**! CNN을 구성하는 모든 layer의 forward pass 를 구현을 완료하였습니다!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "2016550030조상민_CNN_.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "coursera": {
      "course_slug": "convolutional-neural-networks",
      "graded_item_id": "qO8ng",
      "launcher_item_id": "7XDi8"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}